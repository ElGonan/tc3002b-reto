{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "87ee7c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todos los imports\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ce1263a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                pair  verdict\n",
      "0  2470b521_f6ca6fc8        0\n",
      "1  a8e2cefc_ee270b2a        0\n",
      "2  90f01508_e00b1794        0\n",
      "3  16857116_f3d7ce08        1\n",
      "4  51151974_c23278ec        0\n",
      "Columnas del DataFrame después de la unión: Index(['pair', 'verdict'], dtype='object')\n",
      "                pair  verdict\n",
      "0  2470b521_f6ca6fc8        0\n",
      "1  a8e2cefc_ee270b2a        0\n",
      "2  90f01508_e00b1794        0\n",
      "3  16857116_f3d7ce08        1\n",
      "4  51151974_c23278ec        0\n",
      "                pair  verdict  \\\n",
      "0  2470b521_f6ca6fc8        0   \n",
      "1  a8e2cefc_ee270b2a        0   \n",
      "2  90f01508_e00b1794        0   \n",
      "3  16857116_f3d7ce08        1   \n",
      "4  51151974_c23278ec        0   \n",
      "\n",
      "                                               code1  \\\n",
      "0  import com.sun.security.jgss.GSSUtil;\\n\\nimpor...   \n",
      "1  import java.io.*;\\nimport java.sql.SQLOutput;\\...   \n",
      "2  import java.io.*; \\nimport java.util.*;\\n\\npub...   \n",
      "3  import javax.swing.plaf.IconUIResource;\\nimpor...   \n",
      "4  import java.io.*;\\nimport java.util.*;\\n publi...   \n",
      "\n",
      "                                               code2  \n",
      "0  import java.util.*;\\nimport java.io.*;\\n\\npubl...  \n",
      "1  import java.util.*;\\n\\npublic class D{\\n    pr...  \n",
      "2  import java.util.*;\\nimport java.io.*;\\n\\npubl...  \n",
      "3  import javax.swing.plaf.IconUIResource;\\nimpor...  \n",
      "4  import java.io.*;\\nimport java.sql.Array;\\nimp...  \n"
     ]
    }
   ],
   "source": [
    "# ConPlag dataset import\n",
    "\n",
    "def loadConPlag(train_path, test_path, labels_path):\n",
    "    # Cargar los pares de entrenamiento y prueba\n",
    "    train_pairs = pd.read_csv(train_path, header=None, names=['pair'])\n",
    "    test_pairs = pd.read_csv(test_path, header=None, names=['pair'])\n",
    "\n",
    "    # Cargar las etiquetas\n",
    "    labels = pd.read_csv(labels_path)\n",
    "    labels['pair'] = labels['sub1'] + '_' + labels['sub2']\n",
    "\n",
    "    # Unir las etiquetas con los pares de entrenamiento y prueba\n",
    "    train_pairs = train_pairs.merge(labels[['pair', 'verdict']], on='pair', how='left')\n",
    "    test_pairs = test_pairs.merge(labels[['pair', 'verdict']], on='pair', how='left')\n",
    "\n",
    "    return train_pairs, test_pairs\n",
    "\n",
    "# Cargar los datos\n",
    "train_pairs, test_pairs = load_pairs_and_labels(\n",
    "    'datasets/ConPlag/versions/train_pairs.csv',\n",
    "    'datasets/ConPlag/versions/test_pairs.csv',\n",
    "    'datasets/ConPlag/versions/labels.csv'\n",
    ")\n",
    "\n",
    "# Mostrar los primeros registros\n",
    "print(train_pairs.head())\n",
    "print(\"Columnas del DataFrame después de la unión:\", train_pairs.columns)\n",
    "print(train_pairs[['pair', 'verdict']].head())\n",
    "\n",
    "# Función para cargar el código de los pares\n",
    "def load_code(submission_id):\n",
    "    folder_name = submission_id\n",
    "    code1_id, code2_id = folder_name.split('_')\n",
    "\n",
    "    # Rutas de los archivos de código\n",
    "    code1_path = f'datasets/ConPlag/versions/version_2/{folder_name}/{code1_id}.java'\n",
    "    code2_path = f'datasets/ConPlag/versions/version_2/{folder_name}/{code2_id}.java'\n",
    "\n",
    "    # Leer el contenido de los archivos\n",
    "    with open(code1_path, 'r', encoding='utf-8') as file:\n",
    "        code1 = file.read()\n",
    "    with open(code2_path, 'r', encoding='utf-8') as file:\n",
    "        code2 = file.read()\n",
    "\n",
    "    return code1, code2\n",
    "\n",
    "# Cargar los códigos correspondientes a los pares de entrenamiento\n",
    "train_pairs[['sub1', 'sub2']] = train_pairs['pair'].str.split('_', expand=True)\n",
    "train_pairs[['code1', 'code2']] = train_pairs['pair'].apply(lambda x: load_code(x)).apply(pd.Series)\n",
    "\n",
    "print(train_pairs[['pair', 'verdict', 'code1', 'code2']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fcbd1c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              type                                               code\n",
      "0         original  \\npublic class T1 {\\n\\tpublic static void main...\n",
      "1  non-plagiarized  /*\\n * To change this license header, choose L...\n",
      "2  non-plagiarized  \\n/**\\n *\\n * @author 65FBEF05E01FAC390CB3FA07...\n",
      "3  non-plagiarized  \\n\\n/**\\n *\\n * @author CB6AB3315634A1E4D11B09...\n",
      "4  non-plagiarized  /*\\n * To change this license header, choose L...\n"
     ]
    }
   ],
   "source": [
    "# IR-Plag-dataset import\n",
    "def load_ir_plag_dataset(base_path):\n",
    "    data = []\n",
    "\n",
    "    # Recorrer las carpetas case-0n\n",
    "    for case_num in range(1, 8):  # Asumiendo que los casos son del 1 al 7\n",
    "        case_folder = os.path.join(base_path, f'case-0{case_num}')\n",
    "        \n",
    "        # Cargar el archivo original\n",
    "        original_folder = os.path.join(case_folder, 'Original')\n",
    "        original_file = os.listdir(original_folder)[0]  # Solo un archivo\n",
    "        original_code_path = os.path.join(original_folder, original_file)\n",
    "        data.append({'type': 'original', 'code': load_code(original_code_path)})\n",
    "\n",
    "        # Cargar los archivos no plagiados\n",
    "        non_plagiarized_folder = os.path.join(case_folder, 'non-plagiarized')\n",
    "        for folder in os.listdir(non_plagiarized_folder):\n",
    "            folder_path = os.path.join(non_plagiarized_folder, folder)\n",
    "            for java_file in os.listdir(folder_path):\n",
    "                file_path = os.path.join(folder_path, java_file)\n",
    "                if os.path.isfile(file_path):\n",
    "                    data.append({'type': 'non-plagiarized', 'code': load_code(file_path)})\n",
    "\n",
    "        # Cargar los archivos plagiados\n",
    "        plagiarized_folder = os.path.join(case_folder, 'plagiarized')\n",
    "        for folder in os.listdir(plagiarized_folder):\n",
    "            folder_path = os.path.join(plagiarized_folder, folder)\n",
    "            for java_file in os.listdir(folder_path):\n",
    "                file_path = os.path.join(folder_path, java_file)\n",
    "                if os.path.isfile(file_path):\n",
    "                    data.append({'type': 'plagiarized', 'code': load_code(file_path)})\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def load_code(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "# Cargar el IR-Plag-Dataset\n",
    "ir_plag_dataset = load_ir_plag_dataset('datasets/IR-Plag-Dataset')\n",
    "\n",
    "# Mostrar los primeros registros del dataset\n",
    "print(ir_plag_dataset.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
